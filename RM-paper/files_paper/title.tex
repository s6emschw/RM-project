% !TEX root = ../main.tex
\maketitle

\vspace{0.5cm}\begin{abstract}
\begin{center}
\textbf{ABSTRACT}
\end{center}\\
\noindent The prediction accuracy of a traditional least squares model tends to suffer in the presence of multicollinearity and high-dimensionality. A way of dealing with these issues is the use of regularized regression methods, which sacrifice some bias of the estimated model coefficients in exchange for a sufficient reduction in their variance. Using Monte-Carlo simulations, we explore the statistical properties of three main shrinkage methods - ridge, lasso, and the (naive) elastic net. Under our data generation set up, we show that the selection of the most suitable method depends on the degrees of dimensionality, sparsity, and multicollinearity that are present in the sample. We conclude with a real data set application, where we obtain results that are in line with the theoretical discussion of regularized regression and our simulation exercises.\footnote{All the codes and materials are publicly available on GitHub: \url{https://github.com/s6emschw/RM-project}.}\\
\end{abstract}

\setcounter{page}{0}
\thispagestyle{empty}

\pagenumbering{roman}

\newpage
\tableofcontents
\newpage

\listoffigures

\listoftables
\newpage

\pagenumbering{arabic}