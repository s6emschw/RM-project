{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ab9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functools import reduce  \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0ad620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary_files.auxiliary_plots import * \n",
    "from auxiliary_files.auxiliary_analysis import * \n",
    "from auxiliary_files.auxiliary_tables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d2d5d",
   "metadata": {},
   "source": [
    "# 1. High Dimensionality, No Multicollinearity, Varying Sparsity\n",
    "\n",
    "Decreasing sparsity. We expect lasso to initially do better first. As sparsity declines ridge will begin doing better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21181b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_betas = [5, 10, 20, 30, 35]\n",
    "zero_betas = [30, 25, 15, 5, 0]\n",
    "size_non_zero = 2\n",
    "\n",
    "true_betas_list = generate_true_betas(non_zero_betas, zero_betas, size_non_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(900)\n",
    "\n",
    "n = 30\n",
    "p = 35\n",
    "cor_factor = 0 # we have not introduced multicollinearity yet. \n",
    "iterations = 500\n",
    "alphas = np.logspace(-4,1,200)\n",
    "\n",
    "store_X_test = []\n",
    "store_y_test = []\n",
    "\n",
    "\n",
    "for i in true_betas_list: \n",
    "        \n",
    "    y_test, X_test, df_test= get_sim_data(n, p, cor_factor, i) # get training data\n",
    "    store_X_test.append(X_test)\n",
    "    store_y_test.append(y_test)\n",
    "    \n",
    "\n",
    "df_predictions_case_1_5 = get_predictions(n, p, true_betas_list[0], cor_factor, iterations, alphas, store_X_test[0])\n",
    "df_predictions_case_1_10 = get_predictions(n, p, true_betas_list[1], cor_factor, iterations, alphas, store_X_test[1])\n",
    "df_predictions_case_1_20 = get_predictions(n, p, true_betas_list[2], cor_factor, iterations, alphas, store_X_test[2])\n",
    "df_predictions_case_1_30 = get_predictions(n, p, true_betas_list[3], cor_factor, iterations, alphas, store_X_test[3])\n",
    "df_predictions_case_1_35 = get_predictions(n, p, true_betas_list[4], cor_factor, iterations, alphas, store_X_test[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e686f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mse_case_1_5, store_variance_case_1_5, store_bias_sq_case_1_5 = compute_mse(df_predictions_case_1_5, store_y_test[0], iterations)\n",
    "store_mse_case_1_10, store_variance_case_1_10, store_bias_sq_case_1_10 = compute_mse(df_predictions_case_1_10, store_y_test[1], iterations)\n",
    "store_mse_case_1_20, store_variance_case_1_20, store_bias_sq_case_1_20 = compute_mse(df_predictions_case_1_20, store_y_test[2], iterations)\n",
    "store_mse_case_1_30, store_variance_case_1_30, store_bias_sq_case_1_30 = compute_mse(df_predictions_case_1_30, store_y_test[3], iterations)\n",
    "store_mse_case_1_35, store_variance_case_1_35, store_bias_sq_case_1_35 = compute_mse(df_predictions_case_1_35, store_y_test[4], iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6adfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_1_10:\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    mse = ax.plot(alphas, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "mse_1 = ax.plot(alphas, store_mse_case_1_20[1])\n",
    "mse_2 = ax.plot(alphas, store_mse_case_1_20[0])\n",
    "\n",
    "ax.legend([\"mse_1\",\"mse_2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61690960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso does best, which is what we expect!\n",
    "\n",
    "for i in store_mse_case_1_5: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea99faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso does best, which is what we expect!\n",
    "\n",
    "for i in store_mse_case_1_10: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65169c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso starts doing not so well as sparsity decreases. Here, one of the elastic net models would be best. \n",
    "\n",
    "for i in store_mse_case_1_20: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso starts doing not so well as sparsity decreases. Here, one of the elastic net models would be best. \n",
    "\n",
    "for i in store_mse_case_1_30: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge does best as we would expect!\n",
    "\n",
    "for i in store_mse_case_1_35: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b4b0f",
   "metadata": {},
   "source": [
    "# 2. Low Dimensionality, Moderate to High Multicollineary, Varying Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24925599",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_betas_2 = [2, 3, 4, 5, 10]\n",
    "zero_betas_2 = [8, 7, 6, 5, 0]\n",
    "size_non_zero = 2\n",
    "\n",
    "true_betas_list_2 = generate_true_betas(non_zero_betas_2, zero_betas_2, size_non_zero)\n",
    "true_betas_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8fc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(900)\n",
    "\n",
    "n = 30\n",
    "p = 10\n",
    "cor_factor = 0.8 \n",
    "iterations = 500\n",
    "alphas = np.logspace(-4,1,200)\n",
    "\n",
    "store_X_test = []\n",
    "store_y_test = []\n",
    "\n",
    "\n",
    "for i in true_betas_list_2: \n",
    "        \n",
    "    y_test, X_test, df_test= get_sim_data(n, p, cor_factor, i) # get training data\n",
    "    store_X_test.append(X_test)\n",
    "    store_y_test.append(y_test)\n",
    "    \n",
    "\n",
    "df_predictions_case_2_2 = get_predictions(n, p, true_betas_list_2[0], cor_factor, iterations, alphas, store_X_test[0])\n",
    "df_predictions_case_2_3 = get_predictions(n, p, true_betas_list_2[1], cor_factor, iterations, alphas, store_X_test[1])\n",
    "df_predictions_case_2_4 = get_predictions(n, p, true_betas_list_2[2], cor_factor, iterations, alphas, store_X_test[2])\n",
    "df_predictions_case_2_5 = get_predictions(n, p, true_betas_list_2[3], cor_factor, iterations, alphas, store_X_test[3])\n",
    "df_predictions_case_2_10 = get_predictions(n, p, true_betas_list_2[4], cor_factor, iterations, alphas, store_X_test[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040387be",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mse_case_2_2, store_variance_case_2_2, store_bias_sq_case_2_2 = compute_mse(df_predictions_case_2_2, store_y_test[0], iterations)\n",
    "store_mse_case_2_3, store_variance_case_2_3, store_bias_sq_case_2_3 = compute_mse(df_predictions_case_2_3, store_y_test[1], iterations)\n",
    "store_mse_case_2_4, store_variance_case_2_4, store_bias_sq_case_2_4 = compute_mse(df_predictions_case_2_4, store_y_test[2], iterations)\n",
    "store_mse_case_2_5, store_variance_case_2_5, store_bias_sq_case_2_5 = compute_mse(df_predictions_case_2_5, store_y_test[3], iterations)\n",
    "store_mse_case_2_10, store_variance_case_2_10, store_bias_sq_case_2_10 = compute_mse(df_predictions_case_2_10, store_y_test[4], iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceeacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_2_2:\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    mse = ax.plot(alphas, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso does best as we would expect!\n",
    "\n",
    "for i in store_mse_case_2_2: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?\n",
    "\n",
    "for i in store_mse_case_2_3: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?\n",
    "\n",
    "for i in store_mse_case_2_4: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868dd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso still does well here. \n",
    "\n",
    "for i in store_mse_case_2_5: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc030bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge does best here, as we would expect! \n",
    "\n",
    "for i in store_mse_case_2_10: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ee659",
   "metadata": {},
   "source": [
    "# 3. Low Dimensionality, High Sparsity, Varying Degrees of Multicollineary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(123)\n",
    "#np.random.seed(190)\n",
    "#np.random.seed(200)\n",
    "np.random.seed(210)\n",
    "#np.random.seed(66)\n",
    "\n",
    "\n",
    "n = 20 \n",
    "p = 8 \n",
    "true_betas = [3, 1.5, 0, 0, 2, 0, 0, 0]\n",
    "cor_factor = [0, 0.1, 0.3, 0.5, 0.7, 0.8]\n",
    "iterations = 500\n",
    "alphas = np.logspace(-4,1,200)\n",
    "\n",
    "store_X_test = []\n",
    "store_y_test = []\n",
    "\n",
    "\n",
    "for i in cor_factor: \n",
    "\n",
    "    y_test, X_test, df_test= get_sim_data(n, p, i, true_betas) # get training data\n",
    "    store_X_test.append(X_test)\n",
    "    store_y_test.append(y_test)\n",
    "\n",
    "df_predictions_case_3_1 = get_predictions(n, p, true_betas, cor_factor[0], iterations, alphas, store_X_test[0])\n",
    "df_predictions_case_3_2 = get_predictions(n, p, true_betas, cor_factor[1], iterations, alphas, store_X_test[1])\n",
    "df_predictions_case_3_3 = get_predictions(n, p, true_betas, cor_factor[2], iterations, alphas, store_X_test[2])\n",
    "df_predictions_case_3_4 = get_predictions(n, p, true_betas, cor_factor[3], iterations, alphas, store_X_test[3])\n",
    "df_predictions_case_3_5 = get_predictions(n, p, true_betas, cor_factor[4], iterations, alphas, store_X_test[4])\n",
    "df_predictions_case_3_6 = get_predictions(n, p, true_betas, cor_factor[5], iterations, alphas, store_X_test[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mse_case_3_1, store_variance_case_3_1, store_bias_sq_case_3_1 = compute_mse(df_predictions_case_3_1, store_y_test[0], iterations)\n",
    "store_mse_case_3_2, store_variance_case_3_2, store_bias_sq_case_3_2 = compute_mse(df_predictions_case_3_2, store_y_test[1], iterations)\n",
    "store_mse_case_3_3, store_variance_case_3_3, store_bias_sq_case_3_3 = compute_mse(df_predictions_case_3_3, store_y_test[2], iterations)\n",
    "store_mse_case_3_4, store_variance_case_3_4, store_bias_sq_case_3_4 = compute_mse(df_predictions_case_3_4, store_y_test[3], iterations)\n",
    "store_mse_case_3_5, store_variance_case_3_5, store_bias_sq_case_3_5 = compute_mse(df_predictions_case_3_5, store_y_test[4], iterations)\n",
    "store_mse_case_3_6, store_variance_case_3_6, store_bias_sq_case_3_6 = compute_mse(df_predictions_case_3_6, store_y_test[5], iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16763b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_3_1: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_3_2: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_3_3: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only setting where elastic net outperforms lasso and ridge. (for l1 = 0.5 and 0.7)\n",
    "\n",
    "for i in store_mse_case_3_4: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e76061",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_3_5: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14148bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_3_6: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a241f",
   "metadata": {},
   "source": [
    "# 4. Same in Case 3, but all betas are set to 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d22512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ridge should do best here in all cases\"\"\"\n",
    "\n",
    "np.random.seed(123)\n",
    "#np.random.seed(190)\n",
    "#np.random.seed(200)\n",
    "#np.random.seed(210)\n",
    "#np.random.seed(66)\n",
    "\n",
    "\n",
    "n = 20 \n",
    "p = 8 \n",
    "true_betas = np.repeat(0.85, 8)\n",
    "cor_factor = [0, 0.1, 0.3, 0.5, 0.7, 0.8]\n",
    "iterations = 500\n",
    "alphas = np.logspace(-4,1,200)\n",
    "\n",
    "store_X_test = []\n",
    "store_y_test = []\n",
    "\n",
    "\n",
    "for i in cor_factor: \n",
    "\n",
    "    y_test, X_test, df_test= get_sim_data(n, p, i, true_betas) # get training data\n",
    "    store_X_test.append(X_test)\n",
    "    store_y_test.append(y_test)\n",
    "\n",
    "df_predictions_case_4_1 = get_predictions(n, p, true_betas, cor_factor[0], iterations, alphas, store_X_test[0])\n",
    "df_predictions_case_4_2 = get_predictions(n, p, true_betas, cor_factor[1], iterations, alphas, store_X_test[1])\n",
    "df_predictions_case_4_3 = get_predictions(n, p, true_betas, cor_factor[2], iterations, alphas, store_X_test[2])\n",
    "df_predictions_case_4_4 = get_predictions(n, p, true_betas, cor_factor[3], iterations, alphas, store_X_test[3])\n",
    "df_predictions_case_4_5 = get_predictions(n, p, true_betas, cor_factor[4], iterations, alphas, store_X_test[4])\n",
    "df_predictions_case_4_6 = get_predictions(n, p, true_betas, cor_factor[5], iterations, alphas, store_X_test[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mse_case_4_1, store_variance_case_4_1, store_bias_sq_case_4_1 = compute_mse(df_predictions_case_4_1, store_y_test[0], iterations)\n",
    "store_mse_case_4_2, store_variance_case_4_2, store_bias_sq_case_4_2 = compute_mse(df_predictions_case_4_2, store_y_test[1], iterations)\n",
    "store_mse_case_4_3, store_variance_case_4_3, store_bias_sq_case_4_3 = compute_mse(df_predictions_case_4_3, store_y_test[2], iterations)\n",
    "store_mse_case_4_4, store_variance_case_4_4, store_bias_sq_case_4_4 = compute_mse(df_predictions_case_4_4, store_y_test[3], iterations)\n",
    "store_mse_case_4_5, store_variance_case_4_5, store_bias_sq_case_4_5 = compute_mse(df_predictions_case_4_5, store_y_test[4], iterations)\n",
    "store_mse_case_4_6, store_variance_case_4_6, store_bias_sq_case_4_6 = compute_mse(df_predictions_case_4_6, store_y_test[5], iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82890eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_1: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_2: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50646d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_3: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0192a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_4: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824dfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_5: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a48c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_4_6: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573a110",
   "metadata": {},
   "source": [
    "# 5. High Dimensionality, High Sparsity, Varying Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(123) works fine! \n",
    "np.random.seed(190)\n",
    "#np.random.seed(200)\n",
    "#np.random.seed(210)\n",
    "#np.random.seed(66)\n",
    "\n",
    "non_zero_betas = [10]\n",
    "zero_betas = [25]\n",
    "size_non_zero = 2\n",
    "true_betas_hd = generate_true_betas(non_zero_betas, zero_betas, size_non_zero)\n",
    "\n",
    "n = 30\n",
    "p = 35 \n",
    "cor_factor = [0, 0.1, 0.3, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9]\n",
    "iterations = 500\n",
    "alphas = np.logspace(-4,1,200)\n",
    "\n",
    "store_X_test = []\n",
    "store_y_test = []\n",
    "\n",
    "for i in cor_factor: \n",
    "\n",
    "    y_test, X_test, df_test= get_sim_data(n, p, i, true_betas_hd[0]) # get training data\n",
    "    store_X_test.append(X_test)\n",
    "    store_y_test.append(y_test)\n",
    "\n",
    "df_predictions_case_5_1 = get_predictions(n, p, true_betas_hd[0], cor_factor[0], iterations, alphas, store_X_test[0])\n",
    "df_predictions_case_5_2 = get_predictions(n, p, true_betas_hd[0], cor_factor[1], iterations, alphas, store_X_test[1])\n",
    "df_predictions_case_5_3 = get_predictions(n, p, true_betas_hd[0], cor_factor[2], iterations, alphas, store_X_test[2])\n",
    "df_predictions_case_5_4 = get_predictions(n, p, true_betas_hd[0], cor_factor[3], iterations, alphas, store_X_test[3])\n",
    "df_predictions_case_5_5 = get_predictions(n, p, true_betas_hd[0], cor_factor[4], iterations, alphas, store_X_test[4])\n",
    "df_predictions_case_5_6 = get_predictions(n, p, true_betas_hd[0], cor_factor[5], iterations, alphas, store_X_test[5])\n",
    "df_predictions_case_5_7 = get_predictions(n, p, true_betas_hd[0], cor_factor[6], iterations, alphas, store_X_test[6])\n",
    "df_predictions_case_5_8 = get_predictions(n, p, true_betas_hd[0], cor_factor[7], iterations, alphas, store_X_test[7])\n",
    "df_predictions_case_5_9 = get_predictions(n, p, true_betas_hd[0], cor_factor[8], iterations, alphas, store_X_test[8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_mse_case_5_1, store_variance_case_5_1, store_bias_sq_case_5_1 = compute_mse(df_predictions_case_5_1, store_y_test[0], iterations)\n",
    "store_mse_case_5_2, store_variance_case_5_2, store_bias_sq_case_5_2 = compute_mse(df_predictions_case_5_2, store_y_test[1], iterations)\n",
    "store_mse_case_5_3, store_variance_case_5_3, store_bias_sq_case_5_3 = compute_mse(df_predictions_case_5_3, store_y_test[2], iterations)\n",
    "store_mse_case_5_4, store_variance_case_5_4, store_bias_sq_case_5_4 = compute_mse(df_predictions_case_5_4, store_y_test[3], iterations)\n",
    "store_mse_case_5_5, store_variance_case_5_5, store_bias_sq_case_5_5 = compute_mse(df_predictions_case_5_5, store_y_test[4], iterations)\n",
    "store_mse_case_5_6, store_variance_case_5_6, store_bias_sq_case_5_6 = compute_mse(df_predictions_case_5_6, store_y_test[5], iterations)\n",
    "store_mse_case_5_7, store_variance_case_5_7, store_bias_sq_case_5_7 = compute_mse(df_predictions_case_5_7, store_y_test[6], iterations)\n",
    "store_mse_case_5_8, store_variance_case_5_8, store_bias_sq_case_5_8 = compute_mse(df_predictions_case_5_8, store_y_test[7], iterations)\n",
    "store_mse_case_5_9, store_variance_case_5_9, store_bias_sq_case_5_9 = compute_mse(df_predictions_case_5_9, store_y_test[8], iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e65375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in store_mse_case_5_1: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in store_mse_case_5_2: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in store_mse_case_5_3: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f847c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in store_mse_case_5_4: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in store_mse_case_5_5: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in store_mse_case_5_6: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in store_mse_case_5_7: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_5_8: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_mse_case_5_9: \n",
    "    \n",
    "    print(min(i), alphas[np.argmin(i)], np.argmin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d5c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
